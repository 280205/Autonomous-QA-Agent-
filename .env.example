# LLM Configuration
# Option 1: Use OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Option 2: Use Groq (free and fast)
GROQ_API_KEY=your_groq_api_key_here

# Option 3: Use local Ollama
OLLAMA_BASE_URL=http://localhost:11434

# Choose your LLM provider: openai, groq, or ollama
LLM_PROVIDER=groq

# Model names
OPENAI_MODEL=gpt-3.5-turbo
GROQ_MODEL=mixtral-8x7b-32768
OLLAMA_MODEL=llama2

# Embedding model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Vector DB
CHROMA_DB_PATH=./chroma_db

# Server Configuration
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
